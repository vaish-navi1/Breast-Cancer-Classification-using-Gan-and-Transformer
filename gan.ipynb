{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18fea0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vgg16\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, ToPILImage\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Optimized U-Net Generator\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "\n",
    "        def down_block(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.InstanceNorm2d(out_c, affine=True),  \n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "\n",
    "        def up_block(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_c, out_c, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.InstanceNorm2d(out_c, affine=True),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            down_block(in_channels, 64),\n",
    "            down_block(64, 128),\n",
    "            down_block(128, 256),\n",
    "            down_block(256, 512)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            up_block(512, 256),\n",
    "            up_block(256, 128),\n",
    "            up_block(128, 64),\n",
    "            nn.ConvTranspose2d(64, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = self.encoder(x)\n",
    "        return self.decoder(enc)\n",
    "\n",
    "\n",
    "# PatchGAN Discriminator\n",
    "class PatchGANDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(PatchGANDiscriminator, self).__init__()\n",
    "\n",
    "        def disc_block(in_c, out_c, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, kernel_size=4, stride=stride, padding=1, bias=False),\n",
    "                nn.InstanceNorm2d(out_c, affine=True),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            disc_block(in_channels, 64, 2),\n",
    "            disc_block(64, 128, 2),\n",
    "            disc_block(128, 256, 2),\n",
    "            nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Perceptual Loss (VGG-16)\n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        vgg = vgg16(pretrained=True).features[:16]  \n",
    "        for param in vgg.parameters():\n",
    "            param.requires_grad = False  \n",
    "        self.vgg = vgg\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return nn.MSELoss()(self.vgg(x), self.vgg(y))\n",
    "\n",
    "\n",
    "# Loss Functions\n",
    "def adversarial_loss(fake_pred):\n",
    "    return nn.BCEWithLogitsLoss()(fake_pred, torch.ones_like(fake_pred))\n",
    "\n",
    "\n",
    "def pattern_preserving_loss(real_images, fake_images):\n",
    "    return nn.L1Loss()(fake_images, real_images)\n",
    "\n",
    "\n",
    "def temporal_self_distillation_loss(generator, ema_generator, real_images):\n",
    "    fake_images = generator(real_images)\n",
    "    with torch.no_grad():\n",
    "        ema_fake_images = ema_generator(real_images)\n",
    "    return nn.L1Loss()(fake_images, ema_fake_images)\n",
    "\n",
    "\n",
    "# Train Discriminator\n",
    "def train_discriminator(discriminator, optimizer, real_images, fake_images):\n",
    "    discriminator.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    real_pred = discriminator(real_images)\n",
    "    fake_pred = discriminator(fake_images.detach())\n",
    "\n",
    "    real_loss = nn.BCEWithLogitsLoss()(real_pred, torch.full_like(real_pred, 0.9))  \n",
    "    fake_loss = nn.BCEWithLogitsLoss()(fake_pred, torch.full_like(fake_pred, 0.1))\n",
    "\n",
    "    d_loss = (real_loss + fake_loss) / 2\n",
    "    d_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return d_loss.item()\n",
    "\n",
    "\n",
    "# Train Generator\n",
    "def train_generator(generator, discriminator, optimizer, real_images, perceptual_loss, ema_generator=None):\n",
    "    generator.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    fake_images = generator(real_images)\n",
    "    fake_pred = discriminator(fake_images)\n",
    "\n",
    "    adv_loss = adversarial_loss(fake_pred)\n",
    "    pp_loss = pattern_preserving_loss(real_images, fake_images)\n",
    "\n",
    "    if ema_generator is not None:\n",
    "        with torch.no_grad():\n",
    "            ema_fake_images = ema_generator(real_images)\n",
    "        tsd_loss = nn.L1Loss()(fake_images, ema_fake_images)\n",
    "    else:\n",
    "        tsd_loss = torch.tensor(0.0, device=real_images.device)\n",
    "\n",
    "    pl_loss = perceptual_loss(fake_images, real_images)\n",
    "    g_loss = adv_loss + (50 * pp_loss) + (10 * tsd_loss) + (5 * pl_loss)\n",
    "    g_loss.backward()\n",
    "    optimizer.step()\n",
    "    return g_loss.item(), fake_images\n",
    "\n",
    "# Compute Metrics (SSIM, FSIM)\n",
    "def compute_ssim(fake_image, real_image):\n",
    "    real_image_resized = real_image.resize(fake_image.size)\n",
    "    \n",
    "    fake_image_gray = rgb2gray(np.array(fake_image))\n",
    "    real_image_gray = rgb2gray(np.array(real_image_resized))\n",
    "    return ssim(fake_image_gray, real_image_gray, data_range=fake_image_gray.max() - fake_image_gray.min())\n",
    "\n",
    "def compute_fsim(fake_image, real_image):\n",
    "    real_image_resized = real_image.resize(fake_image.size)\n",
    "    \n",
    "    fake_image_array = np.array(fake_image)\n",
    "    real_image_array = np.array(real_image_resized)\n",
    "    fake_image_gray = rgb2gray(fake_image_array)\n",
    "    real_image_gray = rgb2gray(real_image_array)\n",
    "    \n",
    "    # Calculate FSIM using normalized mean squared error as a proxy (if FSIM implementation is not available)\n",
    "    fsim_value = 1 - mean_squared_error(fake_image_gray.flatten(), real_image_gray.flatten()) / np.max(fake_image_gray)\n",
    "    return fsim_value\n",
    "\n",
    "# Training Function\n",
    "def train_gan(generator, discriminator, folder_path, num_epochs=1000, output_dir=\"generated_images\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    perceptual_loss = PerceptualLoss()\n",
    "    transform = Compose([Resize((256, 256)), ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('png', 'jpg', 'tif', 'jpeg'))]\n",
    "\n",
    "    gen_optimizer = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    disc_optimizer = optim.Adam(discriminator.parameters(), lr=5e-5, betas=(0.5, 0.999))\n",
    "\n",
    "    g_losses, d_losses, ssim_scores, fsim_scores = [], [], [], []\n",
    "\n",
    "    ema_generator = UNetGenerator()\n",
    "    ema_generator.load_state_dict(generator.state_dict())\n",
    "    ema_generator.eval()\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        real_image = transform(image).unsqueeze(0)\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            fake_image = generator(real_image)\n",
    "\n",
    "            d_loss = train_discriminator(discriminator, disc_optimizer, real_image, fake_image)\n",
    "            g_loss, fake_image = train_generator(generator, discriminator, gen_optimizer, real_image, perceptual_loss, ema_generator)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                for ema_param, param in zip(ema_generator.parameters(), generator.parameters()):\n",
    "                    ema_param.data.mul_(0.99).add_(0.01 * param.data)\n",
    "\n",
    "            if epoch == num_epochs:\n",
    "                fake_image_save = ToPILImage()(fake_image.squeeze().cpu())\n",
    "                save_image(fake_image, os.path.join(output_dir, f\"{os.path.basename(image_path)}_epoch_{epoch}.png\"), normalize=True)\n",
    "\n",
    "                ssim_score = compute_ssim(fake_image_save, image)\n",
    "                fsim_score = compute_fsim(fake_image_save, image)\n",
    "\n",
    "                g_losses.append(g_loss)\n",
    "                d_losses.append(d_loss)\n",
    "                ssim_scores.append(ssim_score)\n",
    "                fsim_scores.append(fsim_score)\n",
    "\n",
    "                print(f\"\\n Image: {os.path.basename(image_path)} |Generator Loss: {g_loss:.4f} |Discriminator Loss: {d_loss:.4f} \")\n",
    "                print(f\"SSIM: {ssim_score:.4f} | FSIM: {fsim_score:.4f}\")\n",
    "\n",
    " \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(g_losses, label=\"Generator Loss\")\n",
    "    plt.plot(d_losses, label=\"Discriminator Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(ssim_scores, label=\"SSIM Score\")\n",
    "    plt.plot(fsim_scores, label=\"FSIM Score\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run the Training\n",
    "if __name__ == \"__main__\":\n",
    "    generator, discriminator = UNetGenerator(), PatchGANDiscriminator()\n",
    "    train_gan(generator, discriminator, r\"F:\\final year project\\deb\", num_epochs=1000, output_dir=r\"E:\\DEB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
