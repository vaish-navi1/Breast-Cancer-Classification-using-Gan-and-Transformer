{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899d5af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import rgb2lab\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset paths\n",
    "def load_dataset_paths(root_dir):\n",
    "    image_paths = []\n",
    "    class_names = sorted(os.listdir(root_dir))  \n",
    "    class_to_label = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "    label_to_class = {idx: class_name for class_name, idx in class_to_label.items()}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "                    image_paths.append((os.path.join(class_dir, filename), class_to_label[class_name]))\n",
    "\n",
    "    return image_paths, class_to_label, label_to_class\n",
    "\n",
    "# Build Tissue Graph\n",
    "def build_tissue_graph(image, segments):\n",
    "    rag = nx.Graph()\n",
    "    image_lab = rgb2lab(image)\n",
    "    regions = sorted(np.unique(segments))\n",
    "    node_map = {region: idx for idx, region in enumerate(regions)}\n",
    "\n",
    "    for region, idx in node_map.items():\n",
    "        mask = (segments == region)\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        mean_color = np.mean(image_lab[mask, :], axis=0)\n",
    "        rag.add_node(idx, mean_color=mean_color)\n",
    "\n",
    "    height, width = segments.shape\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            current = segments[i, j]\n",
    "            if j < width - 1 and current != segments[i, j + 1]:\n",
    "                if current in node_map and segments[i, j + 1] in node_map:\n",
    "                    rag.add_edge(node_map[current], node_map[segments[i, j + 1]])\n",
    "            if i < height - 1 and current != segments[i + 1, j]:\n",
    "                if current in node_map and segments[i + 1, j] in node_map:\n",
    "                    rag.add_edge(node_map[current], node_map[segments[i + 1, j]])\n",
    "    return rag, node_map\n",
    "\n",
    "# Extract Node Features\n",
    "def extract_node_features(image, segments, node_map):\n",
    "    resnet = models.resnet34(weights=\"IMAGENET1K_V1\")\n",
    "    resnet = nn.Sequential(*list(resnet.children())[:-1])  # Remove FC layer\n",
    "    resnet.eval()\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    node_features = {}\n",
    "    for region, idx in node_map.items():\n",
    "        mask = (segments == region).astype(np.uint8)\n",
    "        masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "        feature = preprocess(masked_image)\n",
    "        feature = resnet(feature.unsqueeze(0)).squeeze().detach().numpy()\n",
    "        node_features[idx] = feature\n",
    "    return node_features\n",
    "\n",
    "# Dataset Class\n",
    "class BreastCancerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths):\n",
    "        self.image_paths = image_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.image_paths[idx]\n",
    "        image = np.array(Image.open(image_path).convert('RGB'))\n",
    "\n",
    "        segments = slic(image, n_segments=100, compactness=10)\n",
    "        tissue_graph, node_map = build_tissue_graph(image, segments)\n",
    "        node_features = extract_node_features(image, segments, node_map)\n",
    "\n",
    "        x = torch.tensor([node_features[i] for i in sorted(node_features.keys())], dtype=torch.float)\n",
    "        edges = [(node_map[u], node_map[v]) for u, v in tissue_graph.edges() if u in node_map and v in node_map]\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous() if edges else torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "        return Data(x=x, edge_index=edge_index, y=torch.tensor(label))\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        return batch\n",
    "\n",
    "# Graph Neural Network Model\n",
    "class CGTModel(torch.nn.Module):\n",
    "    def __init__(self, in_features=512, hidden_dim=256, num_classes=9):\n",
    "        super(CGTModel, self).__init__()\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(in_features, hidden_dim)\n",
    "        self.conv2 = torch_geometric.nn.GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = torch_geometric.nn.global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Train Model\n",
    "def train_model(train_loader, save_dir, num_epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CGTModel().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader):\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch.x, batch.edge_index, batch.batch)\n",
    "            loss = criterion(outputs, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, f\"model_epoch_{epoch+1}.pth\"))\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# Load Dataset and Split into Train/Test\n",
    "dataset_path = r\"E:\\generate_images\"\n",
    "image_paths, class_to_label, label_to_class = load_dataset_paths(dataset_path)\n",
    "\n",
    "train_paths, test_paths = train_test_split(image_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = BreastCancerDataset(train_paths)\n",
    "test_dataset = BreastCancerDataset(test_paths)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, collate_fn=BreastCancerDataset.collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, collate_fn=BreastCancerDataset.collate_fn)\n",
    "\n",
    "# Train the Model\n",
    "train_model(train_loader, save_dir=\"E:/gan/checkpoints\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07182e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load Trained Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CGTModel().to(device)\n",
    "model.load_state_dict(torch.load(\"E:/gan/checkpoints/model_epoch_20.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Classify Test Samples & Calculate Accuracy\n",
    "def evaluate_model(model, test_loader, label_to_class):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    print(\"\\n Predictions:\")\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch.x, batch.edge_index, batch.batch)\n",
    "            predicted = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            true = batch.y.cpu().numpy()\n",
    "            \n",
    "            true_labels.extend(true)\n",
    "            predicted_labels.extend(predicted)\n",
    "\n",
    "            for pred, actual in zip(predicted, true):\n",
    "                print(f\"Predicted: {label_to_class[pred]} | Actual: {label_to_class[actual]}\")\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Run Evaluation\n",
    "evaluate_model(model, test_loader, label_to_class)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
